\input{../../preamble.tex}
\input{../class_info.tex}

\sethomeworknumber{3}

\begin{document}

\homeworkheader{\classnameandsection}

\begin{problem}{7.3-1}
  Why do we analyze the expected running time of a randomized algorithm and not its worst-case running time?
  \begin{solution}
    Because in the case of the randomized algorithm the randomization creates a probability curve so that we can expect
    that our algorithm will run at approximately the mean case run-time as a result of the randomization. Analyzing the algorithm
    for worst case would be analyzing it for a case that is very unlikely to be repeated over and over.

    This is contrary to other algorithms where the worst case run-time may be no less likely than any other case. And
    given the same set of data its runtime will be the same bound no matter how many times you run the algorithm. In the
    case of randomization the run-time bound changes on the same set of input because of the randomization.
  \end{solution}
\end{problem}

\begin{problem}{8.1-1}
  What is the smallest possible depth of a leaf in a decision tree for a comparison sort?
  \begin{solution}
    We know that for a comparison sort we start with the first element in a list and compare it with the next element.
    If it is greater or equal it goes one way on the decision tree, if it is less than, it goes the other. So when it
    makes the comparison it moves down the tree until there are no more comparisons to be made, this is the leaf of
    depth $d$. So we are looking for the minimum number of comparisons. One such case of this is where the list is
    already in sorted order. Then we would only need to compare the element in the list with the one that comes after it
    (1:2, 2:3,$\ldots$,$n-1$:$n$) giving us $d = n - 1$ comparisons. Other cases (see Figure 8.1 in the book) have
    minimum comparisons as well, but no case would have fewer comparisons than this case.
  \end{solution}
\end{problem} \newpage

\begin{problem}{8.1-2}
  Obtain asymptotically tight bounds on $\lg(n!)$ without using Stirlingâ€™s approximation. Instead, evaluate the
  summation $\sum\limits_{k=1}^n \lg{k}$ using techniques from Section A.2.
  \begin{solution}
    $\lg(n!) = \sum\limits_{k=1}^n \lg{k}$ \\
    An upper bound would be to replace $k$ with $n$ in the summation as follows:
    \vspace{12pt}

    $\sum\limits_{k=1}^n \lg(n) = n \lg n$ which is guaranteed to be larger than $\lg(n!)$
    \vspace{12pt}

    \noindent To get a lower bound we can replace $k$ with $k/2$:
    \vspace{12pt}

    $\sum\limits_{k=1}^n \lg(k/2)$ \\
    \vspace{12pt}

    \noindent So $\sum\limits_{k=1}^n \lg(k/2)$ $\le$ $\lg(n!)$ $\le$ $\sum\limits_{k=1}^n \lg(n)$.
  \end{solution}
\end{problem} \newpage

\begin{problem}{8.1-3}
  Show that there is no comparison sort whose running time is linear for at least half of the $n!$ inputs of length $n$.
  What about a fraction of $1/n$ of the inputs of length n? What about a fraction $1=2^n$?
  \begin{solution}
    $n! \le l \le 2^h$ \\
    $h \ge \lg(n!)$
    \vspace{12pt} \\
    So we have our tree and we want to show that the run-time isn't linear over half the inputs. So we can divide $n!$
    by two.
    \begin{align*}
      \lg(n!/2) &= \lg(n!) - \lg(2) \\
      &= \lg(n!) - 1 \\
      &= \Omega(n\lg(n) - 1) \\
      &= \Omega(n\lg(n))
    \end{align*}
    Similarly:
    \vspace{12pt}
    \begin{align*}
      \lg(n!/n) &= \lg(n!) - \lg(n) \\
      &= \Omega(n\lg(n) - \lg(n)) \\
      &= \Omega(n\lg(n))
    \end{align*}
      Because $n\lg(n)$ is the fastest growing term.
      \vspace{12pt}

      \noindent And Finally:
      \begin{align*}
        \lg(n!/2^n) &= \lg(n!) - \lg(2^n) \\
        &= \lg(n!) - n \\
        &= \Omega(n\lg(n) - n) \\
        &= \Omega(n\lg(n))
      \end{align*}
      Because of the properties of logarithms we can see that there is no linear run-time for fractional inputs listed.
  \end{solution}
\end{problem} \newpage

\begin{problem}{8.1-4}
  Suppose that you are given a sequence of $n$ elements to sort. The input sequence consists of $n=k$ subsequences, each
  containing $k$ elements. The elements in a given subsequence are all smaller than the elements in the succeeding
  subsequence and larger than the elements in the preceding subsequence. Thus, all that is needed to sort the whole
  sequence of length $n$ is to sort the $k$ elements in each of the $n=k$ subsequences. Show an $\Omega(k lg k)$ lower
  bound on the number of comparisons needed to solve this variant of the sorting problem. (Hint: It is not rigorous to
  simply combine the lower bounds for the individual subsequences.)
  \begin{solution}
    The number of leaves in each sub-list is $k!$ So we have $2^h \ge k!$, $h \ge \lg k!$. But we have $n/k$ lists so it
    is $\frac{n}{k} \lg k!$. The result looks at the entire tree (as the hint suggests) while defining the tree as a
    collection of sublists as required by the problem.
    \vspace{12pt}
    \begin{align*}
      \lg k! &= \Omega(k \lg k)\text{ by Equation 3.19} \\
      \frac{n}{k} \lg k! &= \Omega((n/k)k \lg k) = \Omega(n \lg k) \qed
    \end{align*}
  \end{solution}
\end{problem}
\end{document}
